name: Load Testing

on:
  push:
    branches: 
      - main
      - test/** 
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to run tests against'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev

permissions:
  contents: write  

jobs:
  load-test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        
    - name: Install dependencies
      working-directory: qa/load-tests
      run: |
        npm install -g artillery
        npm install
        
    - name: Set target URL
      id: set-url
      run: |
        if [ "${{ github.event.inputs.environment }}" == "dev" ]; then
          echo "TARGET_URL=${{ secrets.DEV_TARGET_URL }}" >> $GITHUB_ENV
        else
          echo "TARGET_URL=${{ secrets.DEV_TARGET_URL }}" >> $GITHUB_ENV
        fi
        
    - name: Run load tests
      id: run-tests
      working-directory: qa/load-tests
      run: |
        echo "Running tests against: $TARGET_URL"
        echo "Branch: ${{ github.ref }}"
        artillery run -e ${{ github.event.inputs.environment || 'dev' }} load-test.yml --output load-test-report.json
      env:
        TARGET_URL: ${{ env.TARGET_URL }}
        
    - name: Check test results
      id: check-results
      working-directory: qa/load-tests
      run: |
        if [ -f "load-test-report.json" ]; then
          echo "has_results=true" >> $GITHUB_OUTPUT
        else
          echo "has_results=false" >> $GITHUB_OUTPUT
        fi
        
    - name: Upload test results
      if: always() && steps.check-results.outputs.has_results == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: load-test-results
        path: qa/load-tests/load-test-report.json
        
    - name: Generate test report
      if: always() && steps.check-results.outputs.has_results == 'true'
      working-directory: qa/load-tests
      run: |
        artillery report load-test-report.json --output load-test-report.html
        
    - name: Upload HTML report
      if: always() && steps.check-results.outputs.has_results == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: load-test-report-html
        path: qa/load-tests/load-test-report.html

    - name: Display test metrics
      if: always()
      working-directory: qa/load-tests
      run: |
        echo "## Load Test Results for Environment: ${{ github.event.inputs.environment || 'dev' }}"
        echo ""
        echo "### Branch"
        echo "- Branch: ${{ github.ref }}"
        echo ""
        echo "### Target URL"
        echo "- URL: $TARGET_URL"
        echo ""
        
        if [ -f "load-test-report.json" ]; then
          echo "### Summary"
          TOTAL_REQUESTS=$(jq -r '.metrics.http.requests.total // 0' load-test-report.json)
          FAILED_REQUESTS=$(jq -r '.metrics.http.responses.codes."5xx" // 0' load-test-report.json)
          
          if [ "$TOTAL_REQUESTS" -gt 0 ]; then
            SUCCESS_RATE=$(echo "scale=2; 100 - ($FAILED_REQUESTS * 100 / $TOTAL_REQUESTS)" | bc)
          else
            SUCCESS_RATE=0
          fi
          
          echo "- Total Requests: $TOTAL_REQUESTS"
          echo "- Failed Requests: $FAILED_REQUESTS"
          echo "- Success Rate: $SUCCESS_RATE%"
          echo ""
          
          echo "### Response Times (ms)"
          MEDIAN_RESPONSE=$(jq -r '.metrics.http.response_time.median // 0' load-test-report.json)
          P95_RESPONSE=$(jq -r '.metrics.http.response_time.p95 // 0' load-test-report.json)
          P99_RESPONSE=$(jq -r '.metrics.http.response_time.p99 // 0' load-test-report.json)
          
          echo "- Median: $MEDIAN_RESPONSE"
          echo "- P95: $P95_RESPONSE"
          echo "- P99: $P99_RESPONSE"
          echo ""
          
          echo "### Performance Analysis"
          echo "#### Response Time Thresholds"
          if (( $(echo "$P95_RESPONSE > 2000" | bc -l) )); then
            echo "⚠️ P95 response time ($P95_RESPONSE ms) exceeds threshold (2000 ms)"
          fi
          if (( $(echo "$P99_RESPONSE > 3000" | bc -l) )); then
            echo "⚠️ P99 response time ($P99_RESPONSE ms) exceeds threshold (3000 ms)"
          fi
          
          echo "#### Error Analysis"
          if [ "$FAILED_REQUESTS" -gt 0 ]; then
            echo "⚠️ Failed requests detected: $FAILED_REQUESTS"
            echo "Error distribution:"
            jq -r '.metrics.http.responses.codes | to_entries | .[] | "- \(.key): \(.value) requests"' load-test-report.json
          fi
          
          echo "### Endpoint Performance"
          echo "#### Slow Endpoints (P95 > 1000ms)"
          jq -r '.metrics.http.response_time.p95 | to_entries | .[] | select(.value > 1000) | "- \(.key): \(.value)ms"' load-test-report.json || echo "No slow endpoints detected"
          
          echo "#### High Error Rate Endpoints (> 5%)"
          jq -r '.metrics.http.responses | to_entries | .[] | select(.value > 0) | "- \(.key): \(.value) errors"' load-test-report.json || echo "No high error rate endpoints detected"
          
          echo "### Recommendations"
          if (( $(echo "$P95_RESPONSE > 2000" | bc -l) )); then
            echo "1. Investigate slow endpoints and optimize response times"
            echo "2. Consider implementing caching for frequently accessed data"
            echo "3. Review database query performance"
          fi
          if [ "$FAILED_REQUESTS" -gt 0 ]; then
            echo "4. Investigate failed requests and implement proper error handling"
            echo "5. Review server logs for error patterns"
          fi
        else
          echo "### Test Status"
          echo "No test results available. The test may have failed to run."
          echo ""
          echo "### Error Details"
          echo "Please check the workflow logs for more information."
        fi